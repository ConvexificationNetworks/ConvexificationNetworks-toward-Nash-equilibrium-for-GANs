{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# これを300 epochほどやろう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: UTF-8\n",
    "# これは成功！（100 epochで十分）\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import initializers\n",
    "from chainer import training\n",
    "from chainer import Variable\n",
    "from chainer import cuda\n",
    "from chainer.dataset import iterator as iterator_module\n",
    "from chainer.training import extensions\n",
    "from chainer.dataset import convert\n",
    "from chainer import Variable\n",
    "#from evaluate import out_generated_image\n",
    "from chainer import variable\n",
    "from data import GmmDataset\n",
    "from utils import out_generated, calcEMD\n",
    "\n",
    "# np = cuda.cupy\n",
    "#random_state = np.random.RandomState(123)\n",
    "\n",
    "\n",
    "# Updater\n",
    "\n",
    "class WGANUpdater(training.StandardUpdater):\n",
    "    def __init__(self, iterator, generator, critic,\n",
    "                 n_c, opt_g, opt_c, lam, lam2, n_hidden, device):\n",
    "        if isinstance(iterator, iterator_module.Iterator):\n",
    "            iterator = {'main': iterator}\n",
    "        self._iterators = iterator\n",
    "        self.generator = generator\n",
    "        self.critic = critic\n",
    "        self.n_c = n_c\n",
    "        self._optimizers = {'generator': opt_g, 'critic': opt_c}\n",
    "        self.lam = lam\n",
    "        self.lam2 = lam2\n",
    "        self.device = device\n",
    "        self.converter = convert.concat_examples\n",
    "        self.iteration = 0\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "    def update_core(self):\n",
    "        batch = self.get_iterator('main').next()\n",
    "        batchsize = len(batch)\n",
    "\n",
    "        # Step1 Generate\n",
    "        z = Variable(np.asarray(self.generator.make_hidden(batchsize)))\n",
    "        #print(z)\n",
    "        x_gen = self.generator(z)\n",
    "        #print(\"iteration is \", self.iteration)\n",
    "        #print(\"x_gen is \", x_gen)\n",
    "        y_gen = self.critic(x_gen)\n",
    "\n",
    "        # Step2 real\n",
    "        x_real = Variable(np.array(batch))\n",
    "        y_real = self.critic(x_real)\n",
    "\n",
    "        # Step3 Compute loss for wgan_gp\n",
    "        eps = np.random.uniform(0, 1, (batchsize, 1)).astype(\"f\")\n",
    "        x_mid = eps * x_real + (1.0 - eps) * x_gen\n",
    "        x_mid_v = Variable(x_mid.data)\n",
    "        y_mid = self.critic(x_mid_v)\n",
    "        dydx = chainer.grad([y_mid], [x_mid_v], enable_double_backprop=True)[0]\n",
    "        dydx = F.sqrt(F.sum(F.square(dydx), axis=1))\n",
    "        loss_gp = self.lam * F.mean_squared_error(dydx, np.ones_like(dydx.data))\n",
    "        loss_cri = F.sum(-y_real) / batchsize\n",
    "        #print(loss_cri)\n",
    "        loss_cri += F.sum(y_gen) / batchsize\n",
    "        \n",
    "        loss_sp = self.lam2 * F.absolute(F.sum(self.critic.inter.W) - 1)\n",
    "        loss_all = loss_cri + loss_gp + loss_sp\n",
    "        \n",
    "        # Step4 Update critic\n",
    "        self.critic.cleargrads()\n",
    "        loss_all.backward()\n",
    "        self._optimizers['critic'].update()\n",
    "\n",
    "        # Step5 Update generator\n",
    "        \n",
    "        if self.iteration % self.n_c == 0:\n",
    "            loss_gen = F.sum(-y_gen) / batchsize\n",
    "            #print(loss_gen)\n",
    "            self.generator.cleargrads()\n",
    "            loss_gen.backward()\n",
    "            self._optimizers['generator'].update()\n",
    "            chainer.reporter.report({'loss/generator': loss_gen})\n",
    "\n",
    "        \"\"\"\n",
    "        if self.iteration < 2500 and self.iteration % 100 == 0:\n",
    "            loss_gen = F.sum(-y_gen) / batchsize\n",
    "            loss_sp = self.lam2 * F.absolute(F.sum(self.generator.inter.W) - 1)\n",
    "            loss_gen += loss_sp\n",
    "            self.generator.cleargrads()\n",
    "            loss_gen.backward()\n",
    "            self._optimizers['generator'].update()\n",
    "            chainer.reporter.report({'loss/generator': loss_gen})\n",
    "\n",
    "        if self.iteration > 2500 and self.iteration % self.n_c == 0:\n",
    "            loss_gen = F.sum(-y_gen) / batchsize\n",
    "            loss_sp = self.lam2 * F.absolute(F.sum(self.generator.inter.W) - 1)\n",
    "            loss_gen += loss_sp\n",
    "            self.generator.cleargrads()\n",
    "            loss_gen.backward()\n",
    "            self._optimizers['generator'].update()\n",
    "            chainer.reporter.report({'loss/generator': loss_gen})\n",
    "        \"\"\"\n",
    "\n",
    "        # Step6 Report\n",
    "        chainer.reporter.report({'loss/critic': loss_cri})\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='WGAN')\n",
    "    parser.add_argument('--batchsize', '-b', type=int, default=64,\n",
    "                        help='Number of images in each mini-batch')\n",
    "    parser.add_argument('--datasize', '-d', type=int, default=10000,\n",
    "                        help='Number of samples')\n",
    "    parser.add_argument('--lam', '-l', type=int, default=0.5,\n",
    "                        help='Hyperparameter of gp')\n",
    "    parser.add_argument('--lam2', '-l2', type=int, default=1.0,\n",
    "                        help='Hyperparameter of gp')\n",
    "    parser.add_argument('--n_hidden', type=int, default=100,\n",
    "                        help='latent variable')\n",
    "    parser.add_argument('--seed', '-s', type=int, default=111,\n",
    "                        help='seed number')\n",
    "    parser.add_argument('--epoch', '-e', type=int, default=300,\n",
    "                        help='Number of sweeps over the dataset to train')\n",
    "    parser.add_argument('--gpu', '-g', type=int, default=-1,\n",
    "                        help='GPU ID (negative value indicates CPU)')\n",
    "    parser.add_argument('--out', '-o', default='result',\n",
    "                        help='Directory to output the result')\n",
    "    parser.add_argument('--resume', '-r', default='',\n",
    "                        help='Resume the training from snapshot')\n",
    "    parser.add_argument('--unit', '-u', type=int, default=1000,\n",
    "                        help='Number of units')\n",
    "    parser.add_argument('--setting', '-set', type=int, default=11,\n",
    "                        help='Number of units')\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    # parameter set\n",
    "    ## Optimizers\n",
    "    alpha = 0.002\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "\n",
    "    ## Network\n",
    "    dim = 2\n",
    "    num_nets = 2\n",
    "    wscale = 0.02\n",
    "\n",
    "    # Networks\n",
    "    generator = Generator(dim, num_nets, args.n_hidden, wscale)\n",
    "    critic = Critic(num_nets, wscale)\n",
    "\n",
    "    if args.gpu >= 0:\n",
    "        chainer.cuda.get_device(args.gpu).use()\n",
    "        generator.to_gpu()\n",
    "        critic.to_gpu()\n",
    "\n",
    "    # Optimizer set\n",
    "    opt_g = chainer.optimizers.Adam(alpha = alpha, beta1 = beta1, beta2 = beta2)\n",
    "    #opt_g = chainer.optimizers.RMSprop(lr=0.00005)\n",
    "    opt_g.setup(generator)\n",
    "    #opt_g.add_hook(chainer.optimizer.WeightDecay(0.00001), 'hook_dec')\n",
    "    opt_g.add_hook(chainer.optimizer.GradientClipping(1))\n",
    "\n",
    "    opt_c = chainer.optimizers.Adam(alpha = alpha, beta1 = beta1, beta2 = beta2)\n",
    "    #opt_c = chainer.optimizers.RMSprop(lr=0.00005)\n",
    "    opt_c.setup(critic)\n",
    "    #opt_c.add_hook(chainer.optimizer.WeightDecay(0.00001), 'hook_dec')\n",
    "    opt_c.add_hook(chainer.optimizer.GradientClipping(1))\n",
    "\n",
    "    # Dataset\n",
    "    \"\"\"\n",
    "    train, test = chainer.datasets.get_mnist(withlabel=False, ndim=3, scale=255.)\n",
    "    train_iter = chainer.iterators.SerialIterator(train, args.batchsize)\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = GmmDataset(args.datasize, args.seed, std=0.02, scale=2)\n",
    "    train_iter = chainer.iterators.SerialIterator(dataset, args.batchsize)\n",
    "\n",
    "    # Trainer\n",
    "    updater = WGANUpdater(train_iter, generator, critic, 5, opt_g, opt_c, args.lam, args.lam2, args.n_hidden, device=args.gpu)\n",
    "    trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n",
    "\n",
    "    # Extensions\n",
    "    # trainer.extend(extensions.dump_graph('wasserstein distance'))\n",
    "    \"\"\"\n",
    "    epoch_interval = (50, 'epoch')\n",
    "    trainer.extend(extensions.snapshot(filename='2dim2snap_epoch_{.updater.epoch}.npz'), trigger=epoch_interval)\n",
    "    trainer.extend(extensions.snapshot_object(generator, '2dim2gensnap_epoch_{.updater.epoch}.npz'), trigger=epoch_interval)\n",
    "    trainer.extend(extensions.snapshot_object(critic, '2dim2dissnap_epoch_{.updater.epoch}.npz'), trigger=epoch_interval)\n",
    "    \"\"\"\n",
    "    \n",
    "    trainer.extend(extensions.LogReport())\n",
    "\n",
    "    trainer.extend(\n",
    "        extensions.PlotReport(['loss/critic'],\n",
    "                              'epoch', file_name='criticloss_2dim%d_2.png' % args.setting))\n",
    "\n",
    "    trainer.extend(\n",
    "        extensions.PlotReport(\n",
    "            ['loss/generator'], 'epoch', file_name='genloss_2dim%d_2.png' % args.setting))\n",
    "\n",
    "    trainer.extend(extensions.PrintReport(\n",
    "        ['epoch', 'loss/critic', 'loss/generator', 'elapsed_time']))\n",
    "\n",
    "    out = \"/Users/keiikegami/Dropbox/research/Imaizumi-Sensei/paper_result/2dim/result%d_2\" % args.setting\n",
    "\n",
    "    trainer.extend(calcEMD(generator), trigger=(1, 'epoch'))\n",
    "    trainer.extend(extensions.LogReport(log_name = \"log_2dim%d_2\" % args.setting))\n",
    "    trainer.extend(out_generated(generator, args.seed + 10, out, radius=2), trigger=(10, 'epoch'))\n",
    "    #trainer.extend(extensions.ProgressBar())\n",
    "\n",
    "    if args.resume:\n",
    "        chainer.serializers.load_npz(args.resume, trainer)\n",
    "\n",
    "    # Run\n",
    "    trainer.run()\n",
    "\n",
    "\n",
    "# orriginal class of link\n",
    "class Intersection2(chainer.Link):\n",
    "\n",
    "    def __init__(self, outdim, numnet):\n",
    "        super(Intersection2, self).__init__()\n",
    "        self.outdim = outdim\n",
    "        self.numnet = numnet\n",
    "        with self.init_scope():\n",
    "            W = chainer.initializers.One()\n",
    "            self.W = variable.Parameter(W)\n",
    "            self.W.initialize((self.numnet, 1))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.outdim == 1:\n",
    "            weight = F.relu(self.W.T)\n",
    "        else:\n",
    "            weight = F.relu(self.make_weight(self.W))\n",
    "\n",
    "        return F.matmul(weight, x)\n",
    "\n",
    "    def make_weight(self, array):\n",
    "        weight_matrix = np.zeros((self.outdim, self.outdim * self.numnet), dtype=np.float32)\n",
    "        for i in range(self.numnet):\n",
    "            q = np.array(array[i, 0].data, dtype=np.float32)\n",
    "            weight_matrix[:, i * self.outdim:(i + 1) * self.outdim] = np.identity(self.outdim, dtype=np.float32) * q\n",
    "        return Variable(weight_matrix)\n",
    "\n",
    "    \n",
    "class Generator(chainer.Chain):\n",
    "\n",
    "    def __init__(self, dim=784, num_nets=784, latent=100, wscale=0.02):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.num_nets = num_nets\n",
    "        self.wscale = wscale\n",
    "        self.n_hidden = latent\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.inter = Intersection2(self.dim, self.num_nets)\n",
    "\n",
    "            for net in range(self.num_nets):\n",
    "                w = chainer.initializers.Normal(self.wscale)\n",
    "                b = chainer.initializers.Normal(self.wscale)\n",
    "\n",
    "                setattr(self, \"l1_{}\".format(net), L.Linear(None, 48, initialW=w, initial_bias=b))\n",
    "                setattr(self, \"l2_{}\".format(net), L.Linear(None, 48, initialW=w, initial_bias=b))\n",
    "                setattr(self, \"l3_{}\".format(net), L.Linear(None, 2, initialW=w, initial_bias=b))\n",
    "\n",
    "                # set batchnormalization\n",
    "                #setattr(self, \"bn1_{}\".format(net), L.BatchNormalization(size=800))\n",
    "\n",
    "    def make_hidden(self, batchsize):\n",
    "        return np.random.uniform(-1, 1, (batchsize, self.n_hidden)).astype(np.float32)\n",
    "\n",
    "    def __call__(self, z, test=False):\n",
    "\n",
    "        for net in range(self.num_nets):\n",
    "            #h = F.relu(getattr(self, 'bn1_{}'.format(net))(getattr(self, 'l1_{}'.format(net))(z)))\n",
    "            h = F.relu(getattr(self, 'l1_{}'.format(net))(z))\n",
    "            h2 = F.relu(getattr(self, 'l2_{}'.format(net))(h))\n",
    "            # ここがreluじゃダメなの自明でしょ\n",
    "            h2 = getattr(self, 'l3_{}'.format(net))(h2)\n",
    "\n",
    "            if net == 0:\n",
    "                X = h2\n",
    "            else:\n",
    "                X = F.concat((X, h2), axis=1)\n",
    "\n",
    "        batchsize = X.shape[0]\n",
    "        X = X.reshape(batchsize, self.num_nets * self.dim)\n",
    "        x = self.inter(X.T).T\n",
    "        #x = Variable(np.reshape(x, (batchsize, 1, 28, 28)))\n",
    "        #x = Variable(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Critic(chainer.Chain):\n",
    "    def __init__(self, num_nets=784, wscale=0.02):\n",
    "        super(Critic, self).__init__()\n",
    "        self.num_nets = num_nets\n",
    "        self.wscale = wscale\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.inter = Intersection2(1, self.num_nets)\n",
    "\n",
    "            for net in range(self.num_nets):\n",
    "                w = chainer.initializers.Normal(self.wscale)\n",
    "                b = chainer.initializers.Normal(self.wscale)\n",
    "\n",
    "                setattr(self, \"l1_{}\".format(net), L.Linear(None, 48, initialW=w, initial_bias=b))\n",
    "                setattr(self, \"l2_{}\".format(net), L.Linear(None, 48, initialW=w, initial_bias=b))\n",
    "                setattr(self, \"l3_{}\".format(net), L.Linear(None, 1, initialW=w, initial_bias=b))\n",
    "\n",
    "                # set batchnormalization\n",
    "                #setattr(self, \"bn1_{}\".format(net), L.BatchNormalization(size=800))\n",
    "                #setattr(self, \"bn2_{}\".format(net), L.BatchNormalization(size=800))\n",
    "\n",
    "    def __call__(self, x, test=False):\n",
    "\n",
    "        x = x.reshape(64, 2)\n",
    "        for net in range(self.num_nets):\n",
    "            # ここでhがnanになることで全てがnanになる（xは確かにnanではない）（そしてそれはその前のupdateでWがnanになってるから）\n",
    "            #h = F.leaky_relu(getattr(self, 'bn1_{}'.format(net))(getattr(self, 'l1_{}'.format(net))(x)))\n",
    "            h = F.leaky_relu(getattr(self, 'l1_{}'.format(net))(x))\n",
    "            h = F.leaky_relu(getattr(self, 'l2_{}'.format(net))(h))\n",
    "            # ここsumやめる\n",
    "            #h2 = F.sum(getattr(self, 'bn2_{}'.format(net))(getattr(self, 'l2_{}'.format(net))(h)), axis=1)\n",
    "            h2 = getattr(self, 'l3_{}'.format(net))(h)\n",
    "\n",
    "            if net == 0:\n",
    "                #Y = h2.reshape(64, 1)\n",
    "                Y = h2\n",
    "\n",
    "            else:\n",
    "                #Y = F.concat((Y, h2.reshape(64, 1)), axis=1)\n",
    "                Y = F.concat((Y, h2), axis = 1)\n",
    "\n",
    "        y = self.inter(Y.T)\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       loss/critic  loss/generator  elapsed_time\n",
      "\u001b[J1           -2.95842     1.34842         3.35822       \n",
      "\u001b[J2           -4.06097     4.02864         7.78699       \n",
      "\u001b[J3           -4.19873     3.64111         12.4905       \n",
      "\u001b[J4           -4.36702     3.0907          17.7042       \n",
      "\u001b[J5           -3.89828     3.71337         23.5644       \n",
      "\u001b[J6           -3.68612     3.99081         29.9001       \n",
      "\u001b[J7           -2.36234     4.51101         36.517        \n",
      "\u001b[J8           -2.3077      9.51512         42.2427       \n",
      "\u001b[J9           -2.28919     12.686          47.9306       \n",
      "\u001b[J10          -2.04593     13.3311         53.4094       \n",
      "\u001b[J11          -1.88287     13.1423         59.3895       \n",
      "\u001b[J12          -1.6314      13.5262         64.8872       \n",
      "\u001b[J13          -1.43448     13.405          70.3123       \n",
      "\u001b[J14          -1.22839     14.0939         75.387        \n",
      "\u001b[J15          -0.961484    14.257          80.651        \n",
      "\u001b[J16          -0.933731    14.9784         86.0527       \n",
      "\u001b[J17          -1.00986     15.3274         91.5757       \n",
      "\u001b[J18          -0.89783     15.0592         96.418        \n",
      "\u001b[J19          -0.86017     15.1653         101.031       \n",
      "\u001b[J20          -0.849587    15.3886         105.569       \n",
      "\u001b[J21          -0.856892    15.0058         110.41        \n",
      "\u001b[J22          -0.783206    14.6867         114.819       \n",
      "\u001b[J23          -0.784006    14.1809         119.221       \n",
      "\u001b[J24          -0.758541    13.8806         123.576       \n",
      "\u001b[J25          -0.699215    12.9688         127.985       \n",
      "\u001b[J26          -0.675081    12.5405         132.321       \n",
      "\u001b[J27          -0.637777    12.1292         136.727       \n",
      "\u001b[J28          -0.624138    11.9522         141.179       \n",
      "\u001b[J29          -0.599603    11.6404         145.531       \n",
      "\u001b[J30          -0.601133    11.2391         149.926       \n",
      "\u001b[J31          -0.644742    11.0713         154.509       \n",
      "\u001b[J32          -0.580322    10.7835         158.933       \n",
      "\u001b[J33          -0.551606    10.7273         163.369       \n",
      "\u001b[J34          -0.547142    10.3977         167.845       \n",
      "\u001b[J35          -0.537166    10.2631         172.314       \n",
      "\u001b[J36          -0.522663    9.9993          176.727       \n",
      "\u001b[J37          -0.500942    10.1005         181.14        \n",
      "\u001b[J38          -0.50466     9.80902         185.505       \n",
      "\u001b[J39          -0.489035    9.7139          189.874       \n",
      "\u001b[J40          -0.472666    9.50301         194.289       \n",
      "\u001b[J41          -0.546028    9.44637         199.037       \n",
      "\u001b[J42          -0.48679     9.15558         203.39        \n",
      "\u001b[J43          -0.45337     9.07359         207.631       \n",
      "\u001b[J44          -0.442899    8.87903         212.155       \n",
      "\u001b[J45          -0.445007    8.95264         216.59        \n",
      "\u001b[J46          -0.44225     8.46914         221.256       \n",
      "\u001b[J47          -0.427241    8.36277         226.008       \n",
      "\u001b[J48          -0.427212    8.2045          230.737       \n",
      "\u001b[J49          -0.423553    8.3036          235.988       \n",
      "\u001b[J50          -0.443724    8.22619         242.142       \n",
      "\u001b[J51          -0.533315    8.38677         247.442       \n",
      "\u001b[J52          -0.450887    8.54955         252.173       \n",
      "\u001b[J53          -0.486479    8.57753         256.585       \n",
      "\u001b[J54          -0.457934    8.1382          261.078       \n",
      "\u001b[J55          -0.443811    7.90098         265.588       \n",
      "\u001b[J56          -0.437298    7.80755         269.914       \n",
      "\u001b[J57          -0.451542    7.69052         274.403       \n",
      "\u001b[J58          -0.43148     7.6103          279.025       \n",
      "\u001b[J59          -0.435959    7.43669         283.713       \n",
      "\u001b[J60          -0.427589    7.33837         288.774       \n",
      "\u001b[J61          -0.507094    7.5657          293.899       \n",
      "\u001b[J62          -0.444943    7.54302         298.922       \n",
      "\u001b[J63          -0.423033    7.58903         303.74        \n",
      "\u001b[J64          -0.420858    7.17004         308.606       \n",
      "\u001b[J65          -0.432548    7.1731          313.392       \n",
      "\u001b[J66          -0.395887    7.44809         318.236       \n",
      "\u001b[J67          -0.403355    7.26481         323.215       \n",
      "\u001b[J68          -0.396113    6.79493         328.03        \n",
      "\u001b[J69          -0.421543    6.73361         332.938       \n",
      "\u001b[J70          -0.392302    6.48386         337.791       \n",
      "\u001b[J71          -0.493774    6.48203         343.114       \n",
      "\u001b[J72          -0.413494    6.49225         348.163       \n",
      "\u001b[J73          -0.408479    6.41703         352.974       \n",
      "\u001b[J74          -0.401408    6.67363         356.975       \n",
      "\u001b[J75          -0.409495    6.6355          360.723       \n",
      "\u001b[J76          -0.408348    6.56276         364.659       \n",
      "\u001b[J77          -0.385806    6.62621         368.281       \n",
      "\u001b[J78          -0.367137    6.5305          371.992       \n",
      "\u001b[J79          -0.384444    6.23912         376.008       \n",
      "\u001b[J80          -0.369616    6.24            379.63        \n",
      "\u001b[J81          -0.471547    6.35661         383.596       \n",
      "\u001b[J82          -0.397216    6.55789         387.114       \n",
      "\u001b[J83          -0.372612    6.44007         390.81        \n",
      "\u001b[J84          -0.345888    6.41287         394.467       \n",
      "\u001b[J85          -0.365829    6.36948         398.166       \n",
      "\u001b[J86          -0.338987    5.91698         401.827       \n",
      "\u001b[J87          -0.363909    5.85149         405.608       \n",
      "\u001b[J88          -0.354059    5.79596         409.302       \n",
      "\u001b[J89          -0.353324    5.67966         413.135       \n",
      "\u001b[J90          -0.33068     5.4969          416.935       \n",
      "\u001b[J91          -0.42431     5.60974         421.072       \n",
      "\u001b[J92          -0.332445    5.64355         424.998       \n",
      "\u001b[J93          -0.33921     5.65482         428.914       \n",
      "\u001b[J94          -0.332527    5.49372         432.764       \n",
      "\u001b[J95          -0.323941    5.29708         436.573       \n",
      "\u001b[J96          -0.321895    5.46086         440.503       \n",
      "\u001b[J97          -0.317753    5.82293         444.22        \n",
      "\u001b[J98          -0.299157    5.92714         447.92        \n",
      "\u001b[J99          -0.306681    5.84215         451.717       \n",
      "\u001b[J100         -0.320669    5.94752         455.453       \n",
      "\u001b[J101         -0.405675    5.95721         459.6         \n",
      "\u001b[J102         -0.309834    5.71174         463.229       \n",
      "\u001b[J103         -0.294557    5.64144         466.977       \n",
      "\u001b[J104         -0.293727    5.63855         470.835       \n",
      "\u001b[J105         -0.29622     5.69985         474.753       \n",
      "\u001b[J106         -0.282701    5.49632         478.563       \n",
      "\u001b[J107         -0.288653    5.33465         482.414       \n",
      "\u001b[J108         -0.279887    5.45555         486.194       \n",
      "\u001b[J109         -0.276202    5.46116         490.114       \n",
      "\u001b[J110         -0.28242     5.29154         493.977       \n",
      "\u001b[J111         -0.356024    5.20764         497.994       \n",
      "\u001b[J112         -0.291604    5.31956         501.827       \n",
      "\u001b[J113         -0.287842    5.21951         505.556       \n",
      "\u001b[J114         -0.261049    4.95511         509.419       \n",
      "\u001b[J115         -0.263421    4.90244         513.144       \n",
      "\u001b[J116         -0.255362    5.05026         516.827       \n",
      "\u001b[J117         -0.252782    5.02934         520.647       \n",
      "\u001b[J118         -0.256457    5.1242          524.483       \n",
      "\u001b[J119         -0.270783    5.32288         528.295       \n",
      "\u001b[J120         -0.272522    5.23189         532.086       \n",
      "\u001b[J121         -0.346374    5.38974         537.053       \n",
      "\u001b[J122         -0.270748    5.54491         541.941       \n",
      "\u001b[J123         -0.239773    5.57457         547.119       \n",
      "\u001b[J124         -0.25881     5.43773         552.228       \n",
      "\u001b[J125         -0.248892    5.42531         557.473       \n",
      "\u001b[J126         -0.246066    5.21939         562.731       \n",
      "\u001b[J127         -0.287845    5.16091         567.707       \n",
      "\u001b[J128         -0.268666    4.99942         572.621       \n",
      "\u001b[J129         -0.270438    4.8535          577.534       \n",
      "\u001b[J130         -0.240517    4.90305         582.786       \n",
      "\u001b[J131         -0.354763    4.99744         588.03        \n",
      "\u001b[J132         -0.27361     4.86757         593.268       \n",
      "\u001b[J133         -0.260045    4.98766         597.964       \n",
      "\u001b[J134         -0.253908    4.92637         602.817       \n",
      "\u001b[J135         -0.225596    4.75557         607.608       \n",
      "\u001b[J136         -0.235908    4.49171         612.364       \n",
      "\u001b[J137         -0.232308    4.5487          617.302       \n",
      "\u001b[J138         -0.228242    4.66727         622.075       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[J139         -0.230832    4.55255         626.958       \n",
      "\u001b[J140         -0.249925    4.57133         631.745       \n",
      "\u001b[J141         -0.330778    4.54203         636.919       \n",
      "\u001b[J142         -0.244481    4.68622         641.76        \n",
      "\u001b[J143         -0.242191    4.39126         646.456       \n",
      "\u001b[J144         -0.239191    4.51099         651.216       \n",
      "\u001b[J145         -0.227539    4.50903         656.019       \n",
      "\u001b[J146         -0.22009     4.30504         660.775       \n",
      "\u001b[J147         -0.23187     4.29383         665.602       \n",
      "\u001b[J148         -0.255794    4.32861         670.433       \n",
      "\u001b[J149         -0.264943    4.4             675.353       \n",
      "\u001b[J150         -0.238836    4.25652         680.203       \n",
      "\u001b[J151         -0.315264    4.35599         685.236       \n",
      "\u001b[J152         -0.231455    4.46855         690.024       \n",
      "\u001b[J153         -0.241384    4.3923          694.984       \n",
      "\u001b[J154         -0.236135    4.44435         699.908       \n",
      "\u001b[J155         -0.21193     4.39474         704.856       \n",
      "\u001b[J156         -0.218226    4.19191         709.761       \n",
      "\u001b[J157         -0.209735    4.15889         714.647       \n",
      "\u001b[J158         -0.20126     4.24126         719.382       \n",
      "\u001b[J159         -0.199243    4.05216         724.199       \n",
      "\u001b[J160         -0.221984    4.04087         728.991       \n",
      "\u001b[J161         -0.343988    4.30133         734.16        \n",
      "\u001b[J162         -0.268633    4.27221         738.918       \n",
      "\u001b[J163         -0.214451    4.42943         743.727       \n",
      "\u001b[J164         -0.206931    4.27911         748.693       \n",
      "\u001b[J165         -0.224175    4.26946         753.636       \n",
      "\u001b[J166         -0.203965    4.15187         758.561       \n",
      "\u001b[J167         -0.201096    4.0506          763.557       \n",
      "\u001b[J168         -0.19358     3.91341         768.667       \n",
      "\u001b[J169         -0.228282    3.90876         773.855       \n",
      "\u001b[J170         -0.227734    3.50695         778.922       \n",
      "\u001b[J171         -0.32114     3.66226         784.222       \n",
      "\u001b[J172         -0.216945    3.79198         789.155       \n",
      "\u001b[J173         -0.23867     3.78948         794.082       \n",
      "\u001b[J174         -0.216657    3.75542         798.964       \n",
      "\u001b[J175         -0.214049    3.67793         803.819       \n",
      "\u001b[J176         -0.222601    3.78871         808.678       \n",
      "\u001b[J177         -0.198169    3.53278         813.644       \n",
      "\u001b[J178         -0.215088    3.65706         818.674       \n",
      "\u001b[J179         -0.216481    3.48227         823.495       \n",
      "\u001b[J180         -0.239211    3.45312         828.791       \n",
      "\u001b[J181         -0.328108    3.59362         834.269       \n",
      "\u001b[J182         -0.208514    3.364           839.513       \n",
      "\u001b[J183         -0.201433    3.53222         844.584       \n",
      "\u001b[J184         -0.180979    3.58855         849.603       \n",
      "\u001b[J185         -0.177198    3.56407         854.595       \n",
      "\u001b[J186         -0.201443    3.46733         859.637       \n",
      "\u001b[J187         -0.221656    3.52846         864.749       \n",
      "\u001b[J188         -0.234953    3.17645         869.768       \n",
      "\u001b[J189         -0.252452    3.68571         875.236       \n",
      "\u001b[J190         -0.254683    3.61088         880.45        \n",
      "\u001b[J191         -0.33168     3.90421         885.741       \n",
      "\u001b[J192         -0.214245    3.48154         891.145       \n",
      "\u001b[J193         -0.212105    3.40873         896.206       \n",
      "\u001b[J194         -0.191788    3.40178         901.055       \n",
      "\u001b[J195         -0.20497     3.43912         905.901       \n",
      "\u001b[J196         -0.190222    3.4858          910.711       \n",
      "\u001b[J197         -0.187294    3.33417         915.616       \n",
      "\u001b[J198         -0.182236    3.30555         920.452       \n",
      "\u001b[J199         -0.197332    3.43414         925.182       \n",
      "\u001b[J200         -0.226138    3.30004         929.968       \n",
      "\u001b[J201         -0.305004    3.30188         935.305       \n",
      "\u001b[J202         -0.213192    3.6146          940.093       \n",
      "\u001b[J203         -0.203171    3.46598         944.995       \n",
      "\u001b[J204         -0.192496    3.43591         949.805       \n",
      "\u001b[J205         -0.186149    3.272           954.748       \n",
      "\u001b[J206         -0.182851    3.234           959.617       \n",
      "\u001b[J207         -0.201186    3.21546         964.513       \n",
      "\u001b[J208         -0.24886     3.56652         969.425       \n",
      "\u001b[J209         -0.24124     3.29229         974.326       \n",
      "\u001b[J210         -0.226493    3.17749         979.248       \n",
      "\u001b[J211         -0.280727    2.87822         984.586       \n",
      "\u001b[J212         -0.215484    3.05013         989.559       \n",
      "\u001b[J213         -0.222023    2.98747         994.737       \n",
      "\u001b[J214         -0.197932    2.8713          999.747       \n",
      "\u001b[J215         -0.200824    2.79724         1004.89       \n",
      "\u001b[J216         -0.209385    2.67658         1009.97       \n",
      "\u001b[J217         -0.210989    2.2072          1014.96       \n",
      "\u001b[J218         -0.201316    2.92873         1019.85       \n",
      "\u001b[J219         -0.184103    2.75512         1025.01       \n",
      "\u001b[J220         -0.165648    2.65968         1030.11       \n",
      "\u001b[J221         -0.242372    2.78272         1035.87       \n",
      "\u001b[J222         -0.187603    2.60787         1041.25       \n",
      "\u001b[J223         -0.181987    2.52063         1046.43       \n",
      "\u001b[J224         -0.166088    2.46879         1051.71       \n",
      "\u001b[J225         -0.176249    2.42415         1056.8        \n",
      "\u001b[J226         -0.187188    2.52527         1061.83       \n",
      "\u001b[J227         -0.156792    2.44584         1067.02       \n",
      "\u001b[J228         -0.159315    2.44297         1072.24       \n",
      "\u001b[J229         -0.186697    2.5319          1077.47       \n",
      "\u001b[J230         -0.173888    2.59309         1082.86       \n",
      "\u001b[J231         -0.257657    2.33159         1088.39       \n",
      "\u001b[J232         -0.187303    2.43567         1093.6        \n",
      "\u001b[J233         -0.209494    2.57285         1098.71       \n",
      "\u001b[J234         -0.237109    2.57759         1103.63       \n",
      "\u001b[J235         -0.209275    2.57502         1108.72       \n",
      "\u001b[J236         -0.16409     2.24353         1113.66       \n",
      "\u001b[J237         -0.187883    2.33059         1119.21       \n",
      "\u001b[J238         -0.212171    2.60113         1124.56       \n",
      "\u001b[J239         -0.184017    2.42268         1129.89       \n",
      "\u001b[J240         -0.194758    1.99209         1135.03       \n",
      "\u001b[J241         -0.273541    2.68997         1140.7        \n",
      "\u001b[J242         -0.17149     2.60828         1145.88       \n",
      "\u001b[J243         -0.168292    2.3815          1151.18       \n",
      "\u001b[J244         -0.171508    2.31272         1156.42       \n",
      "\u001b[J245         -0.186319    2.28947         1161.54       \n",
      "\u001b[J246         -0.166431    2.28892         1166.84       \n",
      "\u001b[J247         -0.179063    2.15019         1172.02       \n",
      "\u001b[J248         -0.152097    2.04689         1177.28       \n",
      "\u001b[J249         -0.167044    2.1081          1182.48       \n",
      "\u001b[J250         -0.168503    2.132           1187.73       \n",
      "\u001b[J251         -0.257739    2.27818         1193.27       \n",
      "\u001b[J252         -0.167393    2.22909         1198.45       \n",
      "\u001b[J253         -0.197938    2.27001         1203.89       \n",
      "\u001b[J254         -0.196114    2.29458         1208.91       \n",
      "\u001b[J255         -0.187325    2.02686         1214.1        \n",
      "\u001b[J256         -0.193472    1.97628         1219.31       \n",
      "\u001b[J257         -0.172267    2.12225         1224.69       \n",
      "\u001b[J258         -0.155695    2.0121          1230.13       \n",
      "\u001b[J259         -0.168501    1.94184         1235.36       \n",
      "\u001b[J260         -0.173319    1.9152          1240.58       \n",
      "\u001b[J261         -0.273989    2.06034         1246.42       \n",
      "\u001b[J262         -0.16957     2.0276          1251.37       \n",
      "\u001b[J263         -0.154155    2.0268          1256.35       \n",
      "\u001b[J264         -0.155895    1.99981         1261.49       \n",
      "\u001b[J265         -0.15268     2.045           1266.67       \n",
      "\u001b[J266         -0.157591    2.01998         1272.43       \n",
      "\u001b[J267         -0.158584    1.98531         1277.88       \n",
      "\u001b[J268         -0.155008    2.01441         1283.12       \n",
      "\u001b[J269         -0.161534    2.07652         1288.73       \n",
      "\u001b[J270         -0.139728    2.16492         1294.22       \n",
      "\u001b[J271         -0.223288    2.12739         1300.49       \n",
      "\u001b[J272         -0.147764    2.11636         1306.01       \n",
      "\u001b[J273         -0.180137    2.12877         1311.47       \n",
      "\u001b[J274         -0.168131    2.00371         1317.4        \n",
      "\u001b[J275         -0.173344    2.0863          1323.41       \n",
      "\u001b[J276         -0.170694    2.00091         1329.74       \n",
      "\u001b[J277         -0.15037     1.9343          1336.14       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[J278         -0.149173    1.87158         1341.94       \n",
      "\u001b[J279         -0.151584    1.9003          1347.5        \n",
      "\u001b[J280         -0.145957    1.8216          1352.96       \n",
      "\u001b[J281         -0.233264    1.8428          1358.87       \n",
      "\u001b[J282         -0.149212    1.9317          1364.42       \n",
      "\u001b[J283         -0.166588    1.8568          1369.81       \n",
      "\u001b[J284         -0.166682    1.67661         1375.4        \n",
      "\u001b[J285         -0.1543      1.72801         1381.27       \n",
      "\u001b[J286         -0.149894    1.85384         1386.93       \n",
      "\u001b[J287         -0.137245    1.929           1391.94       \n",
      "\u001b[J288         -0.13835     2.01394         1396.82       \n",
      "\u001b[J289         -0.151454    2.1266          1401.68       \n",
      "\u001b[J290         -0.164925    2.07326         1406.76       \n",
      "\u001b[J291         -0.243792    2.15086         1412.3        \n",
      "\u001b[J292         -0.154255    2.24664         1417.27       \n",
      "\u001b[J293         -0.16115     2.37786         1422.36       \n",
      "\u001b[J294         -0.137791    2.22294         1427.42       \n",
      "\u001b[J295         -0.128854    2.08234         1432.55       \n",
      "\u001b[J296         -0.128335    2.06227         1437.45       \n",
      "\u001b[J297         -0.167074    2.0139          1442.53       \n",
      "\u001b[J298         -0.174097    2.2966          1447.79       \n",
      "\u001b[J299         -0.172476    2.1144          1452.79       \n",
      "\u001b[J300         -0.154193    2.11854         1457.97       \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
